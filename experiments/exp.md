We have done 3 experiments:

1. Training the model on data without fixing duplicates issue
   * Size of the validation set = 478
   * Size of the training set = 3500
   * Trained with 42 epochs.
   * Trained with kaggle notebook T4 took 4.5 hours.
   * This is the [link](https://huggingface.co/KyrillosIshak/Re-SkinCancer/tree/main/Experiments/exp1) to the experiment data.
2. Training the model on data without fixing duplicates issue
   * Size of the validation set = 478
   * Size of the training set = 7000
   * Trained with 60 epochs.
   * Trained with kaggle notebook T4 took 11 hours.
   * This is the [link](https://huggingface.co/KyrillosIshak/Re-SkinCancer/tree/main/Experiments/exp2) to the experiment data.
3. Training the model on data with fixing duplicates issue
   * Size of the validation set = 453
   * Size of the training set = 7000
   * Trained with 40 epochs.
   * Trained with kaggle notebook p100 took 4 hours.
   * This is the [link](https://huggingface.co/KyrillosIshak/Re-SkinCancer/tree/main/Experiments/exp3) to the experiment data.
