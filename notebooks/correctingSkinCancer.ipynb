{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyrillosishak/re-SkinCancer/blob/main/notebooks/correctingSkinCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mitigating Data Leakage in Skin Cancer Classification with Transfer Learning\n"
      ],
      "metadata": {
        "id": "tz4CHutTbV2p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kv7nJfs5G8d"
      },
      "source": [
        "`Skin Cancer Classification with Transfer Learning` paper that we are discussing uses HAM_10000 dataset.\n",
        "\n",
        "The HAM_10000 dataset is a widely used dataset for dermatological image classification, containing thousands of images of pigmented lesions. While it has been a valuable resource for training machine learning models, recent studies have highlighted significant issues with data leakage due to duplicate images within the dataset. This data leakage can lead to overly optimistic performance estimates and undermine the validity of research findings \\[2\\].\n",
        "\n",
        "In this notebook, we tackle the data leakage problem in the HAM_10000 dataset by addressing the duplicates within the dataset. Notably, insights from the survey paper â€œLeakage and the Reproducibility Crisis in ML-based Scienceâ€ highlighted the issue of data leakage and its detrimental effects on reproducibility in machine learning. This survey also references the study â€œInvestigating the Quality of DermaMNIST and Fitzpatrick17k Dermatological Image Datasets,â€ which provided evidence of duplicate images in dermatological datasets, including `HAM_10000`\\[1\\].\n",
        "\n",
        "Our approach involves two main notebooks: the first reproduces the original paper, and the second focuses on identifying and addressing data leakage in the HAM_10000 dataset. By showing image similarity and identifying duplicates, we will clean the validation dataset and subsequently evaluate the impact on model accuracy and confusion metrics.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "**ðŸ” In this notebook, we will:**\n",
        "\n",
        "1.  Identify Duplicates in `HAM_10000`\n",
        "2.  Clean the Validation Dataset.\n",
        "3.  Evaluate Model Performance on new clean validation data.\n",
        "4.  Discuss Implications."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Duplicates in HAM_10000"
      ],
      "metadata": {
        "id": "2Rs-nRhdbZo4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aChiK6ac5G8j"
      },
      "source": [
        "**`HAM_10000` have severe flaw :**\n",
        "\n",
        "> A caveat of HAM10000, despite its rather large size, is that it contains multiple images of the same lesion captured either from different viewing angles or at different magnification levels\n",
        "\n",
        "> the number of lesions with unique lesion IDs (HAM_xxx) is smaller than the number of images with unique image IDs (ISIC_xxx).\n",
        "\n",
        "> observe that the 10,015 images are in fact derived from only 7,470 unique lesions, and 1,956 of these lesion IDs (âˆ¼26.18%) contains 2 or more images: 1,423 lesions have 2 images, 490 lesions have 3 images, 34 lesions have 4 images, 5 lesions have 5 images, and 6 lesions have 4 images each.\n",
        "\n",
        "> The authors of the paper are using early stopping based on the validation set but do not utilize a separate holdout test set.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/kyrillosishak/re-SkinCancer/main/assets/Near-duplicate_HAM10000.png\" height = 150> <img src = \"https://raw.githubusercontent.com/kyrillosishak/re-SkinCancer/main/assets/Near-duplicate2_HAM10000.png\" height = 150>\n",
        "\n",
        "*This images from \\[2\\].*\n",
        "\n",
        "This results in near-duplicates within the dataset, which can compromise the integrity of any machine learning model trained on it. The presence of near-duplicate images can lead to data leakage, where the model learns to recognize specific lesions rather than generalizing to new, unseen lesions.\n",
        "\n",
        "*The duplicates were identified using a tool called [FastDup](https://github.com/visual-layer/fastdup) in the repository.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nov7Ikq5G8k"
      },
      "outputs": [],
      "source": [
        "# Download the dataset to dir data\n",
        "!curl -L -O -J -H \"X-Dataverse-key:$API_TOKEN\" https://dataverse.harvard.edu/api/access/dataset/:persistentId/?persistentId=doi:10.7910/DVN/DBW86T\n",
        "!unzip -q dataverse_files.zip\n",
        "!mkdir data\n",
        "%cd data\n",
        "!unzip -q ../HAM10000_images_part_1.zip\n",
        "!unzip -q ../HAM10000_images_part_2.zip\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbJKNd8h5G8l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Read the CSV file containing metadata for the HAM10000 dataset\n",
        "meta_data = pd.read_csv('HAM10000_metadata')\n",
        "\n",
        "# Group the image filenames by their class labels ('dx') and convert the groups to a dictionary\n",
        "# The dictionary keys are class labels and the values are lists of image filenames belonging to each class\n",
        "class_files = meta_data.groupby('dx')['image_id'].apply(list).to_dict()\n",
        "\n",
        "# Create a mapping from class names to integer indices\n",
        "# This is useful for converting class labels to numeric format for machine learning tasks\n",
        "label_map = {class_name: idx for idx, class_name in enumerate(class_files.keys())}\n",
        "\n",
        "# Create a list of class names\n",
        "class_names = [class_name for class_name in class_files.keys()]\n",
        "\n",
        "print(\"Class names: \",class_names)\n",
        "print(\"Label map: \",label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean the data\n"
      ],
      "metadata": {
        "id": "_0sNpQQ1bdsS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKP9VUod5G8m"
      },
      "source": [
        "In `HAM_10000` there is problem in the data :\n",
        "\n",
        "1. It contains multiple images of the same lesion captured either from different viewing angles or at different magnification levels\n",
        "\n",
        "  -   To fix this issue we will put the images with the same lesion_id in the train set and the rest of them will be in the validation set\n",
        "\n",
        "2. In the paper has a problem of doing early stopping on validation set without using holdout Testset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsgCFoju5G8m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwiR8njH5G8n"
      },
      "source": [
        "### Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03VXMW1y5G8n"
      },
      "outputs": [],
      "source": [
        "class SkinLesionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom dataset class for loading and transforming images of skin lesions along with their labels.\n",
        "\n",
        "    Args:\n",
        "        image_list (list of str): List of image filenames.\n",
        "        labels (list of int): List of labels corresponding to each image.\n",
        "        transform (callable, optional): Optional transform to be applied on an image sample.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_list, labels, transform=None):\n",
        "        self.image_list = image_list\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_list[idx]\n",
        "        img_path = \"./data/\"+img_path+\".jpg\"\n",
        "        image = PIL.Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYRgg4Gl5G8o"
      },
      "outputs": [],
      "source": [
        "def process_train_val_loader(df, target_size, train_transform, val_transform):\n",
        "    \"\"\"\n",
        "    Processes and prepares the training and validation data loaders.\n",
        "\n",
        "    Args:\n",
        "        target_size (int): The desired number of training images after augmentation.\n",
        "        train_transform (callable): Transformations to be applied to training images.\n",
        "        val_transform (callable): Transformations to be applied to validation images.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the training dataset, validation dataset, training data loader, and validation data loader.\n",
        "    \"\"\"\n",
        "    # Load metadata and initialize lists\n",
        "    class_files = df.groupby('dx')['image_id'].apply(list).to_dict()\n",
        "    label_map = {class_name: idx for idx, class_name in enumerate(class_files.keys())}\n",
        "\n",
        "    train_images, train_labels, val_images, val_labels = [], [], [], []\n",
        "\n",
        "    # Process each class to remove confusing images and handle similar ones\n",
        "    for class_name, image_list in class_files.items():\n",
        "\n",
        "        labels = [label_map[class_name]] * len(image_list)\n",
        "        train_dataset, val_dataset = augment_and_split_data(df, image_list, labels, train_transform, val_transform, target_size)\n",
        "\n",
        "        train_images.extend(train_dataset.image_list)\n",
        "        train_labels.extend(train_dataset.labels)\n",
        "        val_images.extend(val_dataset.image_list)\n",
        "        val_labels.extend(val_dataset.labels)\n",
        "\n",
        "    train_dataset = SkinLesionDataset(train_images, train_labels, transform=train_transform)\n",
        "    val_dataset = SkinLesionDataset(val_images, val_labels, transform=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "    return train_dataset, val_dataset, train_loader, val_loader\n",
        "\n",
        "\n",
        "def augment_and_split_data(df, image_list, label_list, train_transform, val_transform, target_size=300):\n",
        "    \"\"\"\n",
        "    Augments and splits a dataset of images and labels into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing 'image_id' and 'lesion_id' columns.\n",
        "        image_list (list of str): List of image filenames.\n",
        "        label_list (list of int): List of labels corresponding to each image.\n",
        "        train_transform (callable): Transformations to be applied to training images.\n",
        "        val_transform (callable): Transformations to be applied to validation images.\n",
        "        target_size (int, optional): Desired number of training images after augmentation. Default is 300.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the training dataset and validation dataset.\n",
        "    \"\"\"\n",
        "    combined = list(zip(image_list, label_list))\n",
        "    random.shuffle(combined)\n",
        "    image_list[:], label_list[:] = zip(*combined)\n",
        "\n",
        "    lesion_dict = df.set_index('image_id')['lesion_id'].to_dict()\n",
        "    lesion_groups = {lesion_id: [] for lesion_id in lesion_dict.values()}\n",
        "\n",
        "    for img, lbl in combined:\n",
        "        lesion_id = lesion_dict[img]\n",
        "        lesion_groups[lesion_id].append((img, lbl))\n",
        "\n",
        "    train_images_labels, val_images_labels = [], []\n",
        "\n",
        "    for lesion_id, imgs_labels in lesion_groups.items():\n",
        "        if len(val_images_labels) + len(imgs_labels) <= 0.2 * len(image_list) :\n",
        "            val_images_labels.extend(imgs_labels)\n",
        "        else:\n",
        "            train_images_labels.extend(imgs_labels)\n",
        "\n",
        "    train_images, train_labels = zip(*train_images_labels)\n",
        "    val_images, val_labels = zip(*val_images_labels)\n",
        "\n",
        "    if len(train_images) > 360:\n",
        "        train_images = train_images[:360]\n",
        "        train_labels = train_labels[:360]\n",
        "    if len(val_images) > 90:\n",
        "        val_images = val_images[:90]\n",
        "        val_labels = val_labels[:90]\n",
        "\n",
        "    augmented_images, augmented_labels = [], []\n",
        "    while len(augmented_images) < target_size:\n",
        "        for img, label in zip(train_images, train_labels):\n",
        "            augmented_images.append(img)\n",
        "            augmented_labels.append(label)\n",
        "            if len(augmented_images) >= target_size:\n",
        "                break\n",
        "\n",
        "    train_dataset = SkinLesionDataset(augmented_images, augmented_labels, transform=train_transform)\n",
        "    val_dataset = SkinLesionDataset(val_images, val_labels, transform=val_transform)\n",
        "\n",
        "    return train_dataset, val_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF_0dxlH5G8p"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=30,\n",
        "        translate=(0.1, 0.1),\n",
        "        scale=None,\n",
        "        shear=10\n",
        "    ),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgOcbNiS5G8p"
      },
      "outputs": [],
      "source": [
        "meta_data = pd.read_csv('HAM10000_metadata')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7R2GzLJ5G8p"
      },
      "outputs": [],
      "source": [
        "number = 1000\n",
        "num_epochs = 100\n",
        "patience = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_dataset, val_dataset, train_loader, val_loader = process_train_val_loader(meta_data, number, train_transform, val_transform)\n",
        "print(\"Size of trainset : \" + str(len(train_dataset.image_list)))\n",
        "print(\"Size of validationset : \" + str(len(val_dataset.image_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jeIqHFh5G8q"
      },
      "source": [
        "After cleaning the data we should use the code in [Reproducing the original paper notebook](../markdowns/reproducingSkinCancer.md) to train the model on the clean data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, train_loader, val_loader, model, optimizer, criterion, patience, early_stopping=True):\n",
        "    \"\"\"Trains a deep learning model for image classification with early stopping.\n",
        "\n",
        "    This function trains a provided model (`model`) on a given dataset (`train_loader`)\n",
        "    for a specified number of epochs (`num_epochs`). It also performs validation\n",
        "    on a separate dataset (`val_loader`) to monitor performance and potentially apply\n",
        "    early stopping to prevent overfitting.\n",
        "\n",
        "    Args:\n",
        "        num_epochs (int): The number of training epochs.\n",
        "        train_loader (torch.utils.data.DataLoader): The data loader for training data.\n",
        "        val_loader (torch.utils.data.DataLoader): The data loader for validation data.\n",
        "        model (torch.nn.Module): The deep learning model to be trained.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer used for updating model weights.\n",
        "        criterion (torch.nn.Module): The loss function used for calculating training loss.\n",
        "        patience (int): The number of epochs to wait for improvement in validation loss\n",
        "            before triggering early stopping (if enabled).\n",
        "        early_stopping (bool, optional): A flag to enable early stopping (default: True).\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: The trained model with the best weights found during validation.\n",
        "    \"\"\"\n",
        "    # Track best validation loss and patience counter for early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Move the model to the specified device (CPU or GPU)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        # Set model to training mode\n",
        "        model.train()\n",
        "\n",
        "        # Initialize running loss for the epoch\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            # Transfer images and labels to the device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # Clear gradients from the previous iteration\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass: predict on the images\n",
        "            outputs = model(images)\n",
        "            # Calculate the loss based on predictions and labels\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Backpropagate the loss to update model weights\n",
        "            loss.backward()\n",
        "            # Update model parameters using the optimizer\n",
        "            optimizer.step()\n",
        "            # Accumulate the training loss for the epoch\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "        # Early stopping\n",
        "        if early_stopping:\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model_weights = copy.deepcopy(model.state_dict())\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    # Load the best model weights\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    model_name = f'{number}'\n",
        "    experiment_dir = '../experiments'\n",
        "    model_directory =  os.path.join(experiment_dir, f'{model_name}.pt')\n",
        "    torch.save({\n",
        "        'model': model.state_dict()\n",
        "    }, model_directory)\n",
        "\n",
        "    print(f\"Model saved to checkpoint: {model_directory} as f'{model_name}.pt\")\n",
        "    print(\"Training and validation completed.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "AZqisX6-7KBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train(num_epochs, train_loader, val_loader, modified_model, optimizer, criterion, patience, early_stopping=True)"
      ],
      "metadata": {
        "id": "zm2C71_Z7OW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Holdout Set for Early Stopping from the Training Dataset\n"
      ],
      "metadata": {
        "id": "PlKQ9b-M_RBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement early stopping effectively, we need to create a separate validation set from the training dataset. This validation set will be used to evaluate the model's performance during training and decide when to stop training early to prevent overfitting.\n",
        "\n",
        "**Datasets Breakdown:**\n",
        "1. Training Dataset: This is the dataset used to train the model. To ensure that the model generalizes well to new data, we will split this dataset into two parts:\n",
        "\n",
        "  - New Training Data: The majority portion of the original training dataset that will continue to be used for training the model.\n",
        "\n",
        "  - Early Stopping Validation Data: A smaller portion of the original training dataset, set aside to validate the model's performance and implement early stopping.\n",
        "\n",
        "2. Validation Dataset: In the context of this setup, the original validation dataset will be repurposed as the test dataset. This test dataset will be used exclusively for evaluating the final model after all training and validation steps are complete.\n",
        "\n",
        "**Process Overview:**\n",
        "1. Split the Original Training Dataset:\n",
        "\n",
        "  - We divide the original training dataset into two parts: a new training set and an early stopping validation set.\n",
        "  - This split ensures that the early stopping process is based on validation data\n",
        "\n",
        "2. Training and Early Stopping:\n",
        "\n",
        "  - Train the model using the new training set.\n",
        "  - Periodically evaluate the model's performance on the early stopping validation set during training.\n",
        "\n",
        "3. Final Model Evaluation:\n",
        "\n",
        "  After training and early stopping, use the test dataset (original validation dataset) to assess the model's final performance. This test dataset serves as an independent evaluation set, providing a measure of how well the model is likely to perform on unseen data.\n"
      ],
      "metadata": {
        "id": "Hj5wZlbm__AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
        "val_size = len(train_dataset) - train_size"
      ],
      "metadata": {
        "id": "-6HFzhPp_Qbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_dataset, early_stopping_val_dataset = random_split(train_dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "OsBBb3ziDhf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for these datasets\n",
        "new_train_loader = DataLoader(new_train_dataset, batch_size=10, shuffle=True)\n",
        "early_stopping_val_loader = DataLoader(early_stopping_val_dataset, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "zodgAElnDxvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will re-train with the `train` function in [Reproducing the original paper notebook](../markdowns/reproducingSkinCancer.md) :\n"
      ],
      "metadata": {
        "id": "5rwP4b1sD1LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train(num_epochs, new_train_loader, early_stopping_val_loader, modified_model, optimizer, criterion, patience, early_stopping=True)"
      ],
      "metadata": {
        "id": "Eev7pkCi7SyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model Performance on new clean validation data"
      ],
      "metadata": {
        "id": "TWigtWpxbinL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We will first show how the model perform after cleanning the data from duplicates"
      ],
      "metadata": {
        "id": "OSjrE4Evbn8v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS6yHkt-5G8q"
      },
      "source": [
        "1.  Downloading the model trained on the cleaned data and the model trained on duplicated data.\n",
        "2.  Downloading the datasets that is used in every model.\n",
        "3.  Evaluate each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCm_bqV25G8q"
      },
      "outputs": [],
      "source": [
        "!wget -q https://huggingface.co/KyrillosIshak/Re-SkinCancer/resolve/main/Experiments/exp4/val_loader_clean_lesion_only.pt\n",
        "!wget -q https://huggingface.co/KyrillosIshak/Re-SkinCancer/resolve/main/Experiments/exp2/val_loader.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr4peTpZ5G8r"
      },
      "outputs": [],
      "source": [
        "val_loader_clean = torch.load('val_loader_clean_lesion_only.pt')\n",
        "val_loader = torch.load('val_loader.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3yMVOZE5G8r"
      },
      "outputs": [],
      "source": [
        "!wget -q https://huggingface.co/KyrillosIshak/Re-SkinCancer/resolve/main/Experiments/exp4/1000_clean_lesion_only.pt\n",
        "!wget -q https://huggingface.co/KyrillosIshak/Re-SkinCancer/resolve/main/Experiments/exp2/1000.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyKl3ScT5G8r"
      },
      "outputs": [],
      "source": [
        "class ModifiedInceptionResNetV2(nn.Module):\n",
        "    \"\"\"ModifiedInceptionResNetV2 class for transfer learning with custom classifier.\n",
        "\n",
        "      This class implements a modified version of the Inception ResNet V2 model for image classification tasks.\n",
        "      It leverages transfer learning by freezing the pre-trained feature extraction layers from a\n",
        "      provided Inception ResNet V2 model and adding a custom classifier on top.\n",
        "\n",
        "      Args:\n",
        "          original_model (torchvision.models.InceptionV3): A pre-trained Inception ResNet V2 model\n",
        "              (typically loaded with `pretrained=True`).\n",
        "          num_classes (int, optional): The number of output classes for the classification task.\n",
        "              Defaults to 7.\n",
        "\n",
        "      Attributes:\n",
        "          features (nn.Sequential): A sequential container holding all layers from the original model\n",
        "              except the final classifier (Softmax layer).\n",
        "          classifier (nn.Sequential): A custom classifier consisting of:\n",
        "              - nn.Flatten(): Flattens the input from the feature extractor.\n",
        "              - nn.Linear(1536, 64): First fully-connected layer with 64 units and ReLU activation.\n",
        "              - nn.Linear(64, num_classes): Second fully-connected layer with 'num_classes' units\n",
        "                and Softmax activation for probability distribution of the classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, original_model, num_classes=7):\n",
        "        super(ModifiedInceptionResNetV2, self).__init__()\n",
        "\n",
        "        # Retain all layers except the final classifier(Softmax)\n",
        "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
        "\n",
        "        # Custom classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # 1536 output from the last layer after removing the classifier\n",
        "            nn.Linear(1536, 64),  # First fully connected layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes),  # Second fully connected layer\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ankkw0Vw5G8s"
      },
      "outputs": [],
      "source": [
        "!pip -q install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA81u8W95G8s"
      },
      "outputs": [],
      "source": [
        "from timm import create_model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = create_model('inception_resnet_v2', pretrained=True,num_classes=7)\n",
        "modified_model = ModifiedInceptionResNetV2(model, num_classes=7)\n",
        "\n",
        "clean_model = copy.deepcopy(modified_model)\n",
        "Dataleaked_model = copy.deepcopy(modified_model)\n",
        "\n",
        "clean_model.load_state_dict(torch.load('1000_clean.pt')['model'])\n",
        "Dataleaked_model.load_state_dict(torch.load('1000.pt')['model'])\n",
        "\n",
        "clean_model.to(device)\n",
        "Dataleaked_model.to(device)\n",
        "\n",
        "clean_model.eval()\n",
        "Dataleaked_model.eval()\n",
        "print(\"Loaded model successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL9HElso5G8s"
      },
      "outputs": [],
      "source": [
        "def get_predictions_and_labels(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return np.array(all_preds), np.array(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAjEb6Yu5G8s"
      },
      "outputs": [],
      "source": [
        "val_preds_duplicates, val_labels_duplicates = get_predictions_and_labels(Dataleaked_model, val_loader, device)\n",
        "val_preds_clean, val_labels_clean = get_predictions_and_labels(clean_model, val_loader_clean, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHy2jFx_5G8t"
      },
      "outputs": [],
      "source": [
        "accuracy_duplicates = np.mean(val_preds_duplicates == val_labels_duplicates)*100\n",
        "accuracy_clean = np.mean(val_preds_clean == val_labels_clean)*100\n",
        "print(f\"Validation Accuracy of the duplicated set: {accuracy_duplicates:.4f}\")\n",
        "print(f\"Validation Accuracy of the clean set: {accuracy_clean:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nt-RYj45G8t"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0iFzgP25G8t"
      },
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cm1 = confusion_matrix(val_labels_duplicates, val_preds_duplicates)\n",
        "cm2 = confusion_matrix(val_labels_clean, val_preds_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6gC3l8f5G8t"
      },
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(cm1, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsrvNcQt5G8t"
      },
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(cm2, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KVY1mQZ5G8t"
      },
      "source": [
        "As we see here, the model tested on images with near-duplicates in the training set achieves higher accuracy than the model tested on clean data, with a validation accuracy of 78.8703% compared to 72.0588%. This discrepancy highlights a significant issue : the presence of near-duplicate images in datasets can artificially inflate performance metrics, leading to misleading conclusions about a modelâ€™s efficacy. This has implications on the reproducibility and reliability of published research. Papers that report inflated performance metrics due to such data issues may set unrealistic benchmarks, making it difficult for subsequent researchers to replicate results or make fair comparisons. To ensure the integrity and credibility of machine learning research, it is crucial to rigorously check for and address near-duplicates and other forms of data leakage before publishing results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Then we will see how the model perform after correctly implementing early stopping"
      ],
      "metadata": {
        "id": "TMmmkAK4bmH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://huggingface.co/KyrillosIshak/Re-SkinCancer/resolve/main/Experiments/exp5/new_val_loader.pt\n",
        "!wget -q https://huggingface.co/KyrillosIshak/Re-SkinCancer/resolve/main/Experiments/exp5/1000_clean_lesion_only.pt"
      ],
      "metadata": {
        "id": "-pKPawNLdIVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.load('new_val_loader.pt')"
      ],
      "metadata": {
        "id": "jhAu0lv-cFPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timm import create_model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = create_model('inception_resnet_v2', pretrained=True,num_classes=7)\n",
        "modified_model = ModifiedInceptionResNetV2(model, num_classes=7)\n",
        "\n",
        "modified_model.load_state_dict(torch.load('1000_clean_lesion_only.pt')['model'])\n",
        "\n",
        "modified_model.to(device)\n",
        "modified_model.eval()\n",
        "print(\"Loaded model successfully.\")"
      ],
      "metadata": {
        "id": "byKjnTDAcOLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds, val_labels = get_predictions_and_labels(modified_model, val_loader, device)\n",
        "accuracy = np.mean(val_preds == val_labels)*100\n",
        "print(f\"Validation Accuracy of the duplicated set: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "gu2vVek2cbpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm1 = confusion_matrix(val_labels, val_preds)\n",
        "plot_confusion_matrix(cm1, class_names)"
      ],
      "metadata": {
        "id": "wqMPwsjAfQBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see after correcting the early stopping the accuracy dropped from 72% to 71%."
      ],
      "metadata": {
        "id": "P6amHyn_gZ9r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWfpN4Pe5G8u"
      },
      "source": [
        "## **Refrences**\n",
        "\n",
        "1.  [Leakage and the Reproducibility Crisis in ML-based Science](https://arxiv.org/abs/2207.07048)\n",
        "\n",
        "2.  [Investigating the Quality of DermaMNIST and Fitzpatrick17k Dermatological Image Dataset](https://arxiv.org/pdf/2401.14497)"
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  }
}